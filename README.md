# Reading Notes

This repository contains my markdown notes of papers on various topics. The notes are organized into different categories for easy navigation.

## Table of Contents

- [Computer Vision](#computer-vision)
- [NLP](#nlp)
- [Visualization/Explainable AI](#visualizationexplainable-ai)
- [ML](#ML)

## Computer Vision

[StyleGAN-NADA: CLIP-Guided Domain Adaptation of Image Generators](https://arxiv.org/pdf/2108.00946.pdf)

[UNDERSTANDING THE MODALITY GAP IN CLIP](https://openreview.net/pdf?id=8W3KGzw7fNI)

[Improved Techniques for Training Score-Based
Generative Models](https://arxiv.org/pdf/2006.09011.pdf)

[Denoising Diffusion Probabilistic Models](https://arxiv.org/pdf/2006.11239.pdf)

[Hierarchical Text-Conditional
Image Generation with CLIP Latents](https://arxiv.org/pdf/2204.06125.pdf)

[Rethinking Bias Mitigation: Fairer Architectures
Make for Fairer Face Recognition](https://openreview.net/attachment?id=1vzF4zWQ1E&name=pdf)

[Skews in the Phenomenon Space Hinder
Generalization in Text-to-Image Generation](https://arxiv.org/pdf/2403.16394) 

- Dalle-3 can't draw "a mouse chasing a cat"

## CLIP (VLM)

[Parts of Speech–Grounded Subspaces in
Vision-Language Models](https://arxiv.org/pdf/2305.14053)

[The Hidden Language of Diffusion Models](https://arxiv.org/pdf/2306.00966)

## NLP

[HotFlip: White-Box Adversarial Examples for Text Classification](https://arxiv.org/pdf/1712.06751.pdf)

[BERT-ATTACK: Adversarial Attack Against BERT Using BERT](https://arxiv.org/pdf/2004.09984.pdf)

[Is BERT Really Robust? A Strong Baseline for Natural Language Attack
on Text Classification and Entailment](https://arxiv.org/pdf/1907.11932.pdf)

[BERTSCORE: EVALUATING TEXT GENERATION WITH
BERT](https://arxiv.org/pdf/1904.09675.pdf)

[Towards Faithfully Interpretable NLP Systems: How Should We Deﬁne and Evaluate Faithfulness?](https://arxiv.org/pdf/2004.03685.pdf)

[Are Emergent Abilities of Large Language Models a Mirage?](https://arxiv.org/pdf/2304.15004.pdf)

[Why think step by step? Reasoning emerges from the
locality of experience](https://openreview.net/attachment?id=rcXXNFVlEn&name=pdf)

[SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT
REASONING IN LANGUAGE MODELS
](https://arxiv.org/pdf/2203.11171)

[Training Language Models to Self-Correct via
Reinforcement Learning](https://arxiv.org/pdf/2409.12917)

- Deepmind

[A Theoretical Understanding of Self-Correction through
In-context Alignmen](https://arxiv.org/pdf/2405.18634)

- Self-correction for safety alignment

[Scaling LLM Test-Time Compute Optimally can
be More Effective than Scaling Model Parameters](https://arxiv.org/pdf/2408.03314)

- Deepmind Scaling Test-time compute

[Universal and Transferable Adversarial Attacks on Aligned Language Models](https://arxiv.org/pdf/2307.15043)

- postfix attack

[Refusal in Language Models
Is Mediated by a Single Direction](https://arxiv.org/pdf/2406.11717)

## Visualization/Explainable AI

[This Looks Like Those: Illuminating Prototypical Concepts Using Multiple Visualizations](This%20Looks%20Like%20Those%3A%20Illuminating%20Prototypical%20Concepts%20Using%20Multiple%20Visualizations.md)

[This Looks Like That: Deep Learning for Interpretable Image Recognition](This%20Looks%20Like%20That%3A%20Deep%20Learning%20for%20Interpretable%20Image%20Recognition.md)

[Look at the Variance! Efficient Black-box
Explanations with Sobol-based Sensitivity Analysis](Look%20at%20the%20Variance!%20Efficient%20Black-box%20Explanations%20with%20Sobol-based%20Sensitivity%20Analysis.md)

["why should i trust you?" explaining the
predictions of any classifier](https://arxiv.org/abs/1602.04938)

[Prompt Valuation Based on Shapley Values](https://arxiv.org/pdf/2312.15395.pdf)

[The elephant in the interpretability room: Why use attention as explanation when we have saliency methods?](https://arxiv.org/pdf/2010.05607.pdf)

[Does Localization Inform Editing? Surprising
Differences in Causality-Based Localization vs.
Knowledge Editing in Language Models
](https://openreview.net/pdf?id=EldbUlZtbd)

[The Linear Representation Hypothesis and
the Geometry of Large Language Models
](https://arxiv.org/pdf/2311.03658)

[INTERPRETING CLIP WITH SPARSE LINEAR CONCEPT EMBEDDINGS](https://arxiv.org/pdf/2402.10376v1)

[DISENTANGLING REGIONAL PRIMITIVES FOR IMAGE GENERATION](https://arxiv.org/pdf/2410.04421)
## ML
[Sharpness Minimization Algorithms Do Not Only Minimize Sharpness To Achieve Better Generalization](https://openreview.net/attachment?id=Dkmpa6wCIx&name=pdf)

[QLORA: Efficient Finetuning of Quantized LLMs](https://openreview.net/attachment?id=OUIFPHEgJU&name=pdf)

## I really like the plots

[Efficient Diffusion Policies for Offline Reinforcement Learning](https://arxiv.org/pdf/2305.20081)
